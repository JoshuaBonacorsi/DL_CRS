{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataprep_utils import MovieDataset\n",
    "from utils.models_utils import DLCRS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype\n",
      "---  ------     --------------   -----\n",
      " 0   userId     100000 non-null  int64\n",
      " 1   movieId    100000 non-null  int64\n",
      " 2   rating     100000 non-null  int64\n",
      " 3   timestamp  100000 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "column_names = ['userId','movieId','rating','timestamp']\n",
    "df = pd.read_csv('./archive/ml-100k/u.data', sep='\\t',header=None,names=column_names)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39muserID\u001b[39m.\u001b[39mvalue_counts())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "len(df.userID.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    34174\n",
       "3    27145\n",
       "5    21201\n",
       "2    11370\n",
       "1     6110\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['rating'] != 0, 'rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user and movie id to start from 0 so we don't run into index out of bound with Embedding\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "df.userId = lbl_user.fit_transform(df.userId.values)\n",
    "df.movieId = lbl_movie.fit_transform(df.movieId.values)\n",
    "\n",
    "df_train, df_valid = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=42, stratify=df.rating.values\n",
    ")\n",
    "\n",
    "train_dataset = MovieDataset(\n",
    "    users=df_train.userId.values,\n",
    "    movies=df_train.movieId.values,\n",
    "    ratings=df_train.rating.values\n",
    ")\n",
    "\n",
    "valid_dataset = MovieDataset(\n",
    "    users=df_valid.userId.values,\n",
    "    movies=df_valid.movieId.values,\n",
    "    ratings=df_valid.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[0;32m      2\u001b[0m                           batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m      3\u001b[0m                           shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m                           num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n\u001b[0;32m      6\u001b[0m validation_loader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mvalid_dataset,\n\u001b[0;32m      7\u001b[0m                           batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[0;32m      8\u001b[0m                           shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                           num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n\u001b[0;32m     11\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(train_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2) \n",
    "\n",
    "validation_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2) \n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "dataloader_data = dataiter.next() \n",
    "print(dataloader_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DLCRS(\n",
    "    n_users=len(lbl_user.classes_),\n",
    "    n_movies=len(lbl_movie.classes_),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())  \n",
    "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lbl_user.classes_))\n",
    "print(len(lbl_movie.classes_))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "total_loss = 0\n",
    "plot_steps, print_steps = 5000, 5000\n",
    "step_cnt = 0\n",
    "all_losses_list = [] \n",
    "\n",
    "model.train() \n",
    "for epoch_i in range(epochs):\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        output = model(train_data[\"users\"], \n",
    "                       train_data[\"movies\"]\n",
    "                      ) \n",
    "        \n",
    "        # .view(4, -1) is to reshape the rating to match the shape of model output which is 4x1\n",
    "        rating = train_data[\"ratings\"].view(4, -1).to(torch.float32)\n",
    "\n",
    "        loss = loss_func(output, rating)\n",
    "        total_loss = total_loss + loss.sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        step_cnt = step_cnt + len(train_data[\"users\"])\n",
    "        \n",
    "\n",
    "        if(step_cnt % plot_steps == 0):\n",
    "            avg_loss = total_loss/(len(train_data[\"users\"]) * plot_steps)\n",
    "            print(f\"epoch {epoch_i} loss at step: {step_cnt} is {avg_loss}\")\n",
    "            all_losses_list.append(avg_loss)\n",
    "            total_loss = 0 # reset total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_output_list = []\n",
    "target_rating_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batched_data in enumerate(validation_loader): \n",
    "        model_output = model(batched_data['users'], \n",
    "                       batched_data[\"movies\"])\n",
    "        \n",
    "        model_output_list.append(model_output.sum().item() / len(batched_data['users']) )\n",
    "\n",
    "        target_rating = batched_data[\"ratings\"]\n",
    "        \n",
    "        target_rating_list.append(target_rating.sum().item() / len(batched_data['users']))\n",
    "\n",
    "        print(f\"model_output: {model_output}, target_rating: {target_rating}\")\n",
    "\n",
    "\n",
    "# squared If True returns MSE value, if False returns RMSE value.\n",
    "rms = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
    "print(f\"rms: {rms}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
